{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE344 Assignment 1 - Part 1: Fuel Consumption → Horsepower Prediction\n",
    "\n",
    "**Dataset**: Fuel Consumption Based on HP (Kaggle)  \n",
    "**Task**: Build regression models to predict horsepower (HP) based on fuel consumption features\n",
    "\n",
    "---\n",
    "\n",
    "## Models to be trained:\n",
    "- Linear Regression\n",
    "- Polynomial Regression (degree 2)\n",
    "- Polynomial Regression (degree 3)\n",
    "- Polynomial Regression (degree 4)\n",
    "\n",
    "**Note**: No regularization (Ridge/Lasso/ElasticNet) will be used as per assignment requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Imports\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load and Inspect the Dataset (10 points)\n",
    "\n",
    "In this section, we:\n",
    "- Load the CSV file into a pandas DataFrame\n",
    "- Display basic information about the dataset:\n",
    "  - Column names\n",
    "  - Shape (number of rows and columns)\n",
    "  - Summary statistics\n",
    "- Check for missing values\n",
    "- Identify the feature and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET OVERVIEW\n",
      "============================================================\n",
      "\n",
      "Shape: (100, 2)\n",
      "\n",
      "Column names:\n",
      "['Horse Power', 'Fuel Economy (MPG)']\n",
      "\n",
      "============================================================\n",
      "SUMMARY STATISTICS\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Horse Power</th>\n",
       "      <th>Fuel Economy (MPG)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>213.676190</td>\n",
       "      <td>23.178501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>62.061726</td>\n",
       "      <td>4.701666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>174.996514</td>\n",
       "      <td>20.439516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>218.928402</td>\n",
       "      <td>23.143192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>251.706476</td>\n",
       "      <td>26.089933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Horse Power  Fuel Economy (MPG)\n",
       "count   100.000000          100.000000\n",
       "mean    213.676190           23.178501\n",
       "std      62.061726            4.701666\n",
       "min      50.000000           10.000000\n",
       "25%     174.996514           20.439516\n",
       "50%     218.928402           23.143192\n",
       "75%     251.706476           26.089933\n",
       "max     350.000000           35.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MISSING VALUES CHECK\n",
      "============================================================\n",
      "Horse Power           0\n",
      "Fuel Economy (MPG)    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Load the dataset\n",
    "# ============================================================\n",
    "\n",
    "DATA_PATH = \"FuelEconomy.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nShape:\", df.shape)\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MISSING VALUES CHECK\")\n",
    "print(\"=\"*60)\n",
    "missing_values = df.isna().sum()\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "From the dataset inspection above:\n",
    "\n",
    "- **Feature (X)**: `Fuel Economy (MPG)` - measures how many miles a vehicle can travel per gallon of fuel\n",
    "- **Target (y)**: `Horse Power` - the engine's horsepower that we want to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Train/Test Split (70% / 30% Random) (5 points)\n",
    "\n",
    "We split the dataset into:\n",
    "- **Training set (70%)**: Used to train the models\n",
    "- **Test set (30%)**: Used to evaluate model performance on unseen data\n",
    "\n",
    "A fixed `random_state=42` ensures reproducibility of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix X shape: (100, 1)\n",
      "Target vector y shape: (100,)\n",
      "\n",
      "============================================================\n",
      "TRAIN/TEST SPLIT SUMMARY\n",
      "============================================================\n",
      "Training samples: 70 (70.0%)\n",
      "Test samples:     30 (30.0%)\n",
      "Total samples:    100\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Prepare features (X) and target (y)\n",
    "# ============================================================\n",
    "\n",
    "# Feature: Fuel Economy (MPG)\n",
    "X = df[['Fuel Economy (MPG)']].values\n",
    "\n",
    "# Target: Horse Power\n",
    "y = df['Horse Power'].values\n",
    "\n",
    "print(\"Feature matrix X shape:\", X.shape)\n",
    "print(\"Target vector y shape:\", y.shape)\n",
    "\n",
    "# ============================================================\n",
    "# Train-test split (70% train, 30% test)\n",
    "# ============================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.30, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAIN/TEST SPLIT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training samples: {X_train.shape[0]} ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test samples:     {X_test.shape[0]} ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Total samples:    {len(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Model Training: Linear + Polynomial Regression (15 points)\n",
    "\n",
    "We will train **four regression models** without any regularization:\n",
    "\n",
    "1. **Linear Regression**: Fits a straight line (degree 1 polynomial)\n",
    "2. **Polynomial Regression (degree 2)**: Fits a quadratic curve\n",
    "3. **Polynomial Regression (degree 3)**: Fits a cubic curve\n",
    "4. **Polynomial Regression (degree 4)**: Fits a quartic curve\n",
    "\n",
    "For polynomial models, we use `PolynomialFeatures` to generate polynomial and interaction features, then apply `LinearRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Train all models\n",
    "# ============================================================\n",
    "\n",
    "# Dictionary to store all trained models\n",
    "models = {}\n",
    "\n",
    "# 1. Linear Regression\n",
    "model_linear = LinearRegression()\n",
    "model_linear.fit(X_train, y_train)\n",
    "models['Linear Regression'] = {\n",
    "    'model': model_linear,\n",
    "    'X_train': X_train,\n",
    "    'X_test': X_test,\n",
    "    'degree': 1\n",
    "}\n",
    "\n",
    "# 2-4. Polynomial Regression (degrees 2, 3, 4)\n",
    "for degree in [2, 3, 4]:\n",
    "    \n",
    "    # Create polynomial features\n",
    "    poly_features = PolynomialFeatures(degree=degree, include_bias=True)\n",
    "    \n",
    "    # Transform training data\n",
    "    X_train_poly = poly_features.fit_transform(X_train)\n",
    "    \n",
    "    # Transform test data (use transform, not fit_transform)\n",
    "    X_test_poly = poly_features.transform(X_test)\n",
    "    \n",
    "    # Train linear regression on polynomial features\n",
    "    model_poly = LinearRegression()\n",
    "    model_poly.fit(X_train_poly, y_train)\n",
    "    \n",
    "    # Store model and transformed data\n",
    "    models[f'Polynomial (degree={degree})'] = {\n",
    "        'model': model_poly,\n",
    "        'X_train': X_train_poly,\n",
    "        'X_test': X_test_poly,\n",
    "        'degree': degree,\n",
    "        'poly_features': poly_features\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Model Evaluation (Train and Test) (10 points)\n",
    "\n",
    "For each model, we compute three key metrics on both training and test sets:\n",
    "\n",
    "- **MSE (Mean Squared Error)**: Average of squared differences between predicted and actual values. Lower is better.\n",
    "- **MAE (Mean Absolute Error)**: Average of absolute differences. Lower is better.\n",
    "- **R² (Coefficient of Determination)**: Proportion of variance explained by the model. Range: (-∞, 1], where 1 is perfect fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "MODEL PERFORMANCE SUMMARY\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Train R²</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>357.699180</td>\n",
       "      <td>16.061689</td>\n",
       "      <td>0.906320</td>\n",
       "      <td>318.561087</td>\n",
       "      <td>14.940628</td>\n",
       "      <td>0.912561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polynomial (degree=2)</td>\n",
       "      <td>350.879731</td>\n",
       "      <td>15.995824</td>\n",
       "      <td>0.908106</td>\n",
       "      <td>331.105434</td>\n",
       "      <td>15.148330</td>\n",
       "      <td>0.909118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polynomial (degree=3)</td>\n",
       "      <td>345.108668</td>\n",
       "      <td>15.746762</td>\n",
       "      <td>0.909618</td>\n",
       "      <td>318.404012</td>\n",
       "      <td>14.764973</td>\n",
       "      <td>0.912604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Polynomial (degree=4)</td>\n",
       "      <td>339.700171</td>\n",
       "      <td>15.508465</td>\n",
       "      <td>0.911034</td>\n",
       "      <td>313.798757</td>\n",
       "      <td>14.735471</td>\n",
       "      <td>0.913868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model   Train MSE  Train MAE  Train R²    Test MSE  \\\n",
       "0      Linear Regression  357.699180  16.061689  0.906320  318.561087   \n",
       "1  Polynomial (degree=2)  350.879731  15.995824  0.908106  331.105434   \n",
       "2  Polynomial (degree=3)  345.108668  15.746762  0.909618  318.404012   \n",
       "3  Polynomial (degree=4)  339.700171  15.508465  0.911034  313.798757   \n",
       "\n",
       "    Test MAE   Test R²  \n",
       "0  14.940628  0.912561  \n",
       "1  15.148330  0.909118  \n",
       "2  14.764973  0.912604  \n",
       "3  14.735471  0.913868  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Evaluate all models\n",
    "# ============================================================\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model_info in models.items():\n",
    "    model = model_info['model']\n",
    "    X_train_transformed = model_info['X_train']\n",
    "    X_test_transformed = model_info['X_test']\n",
    "    \n",
    "    # Training set predictions\n",
    "    y_train_pred = model.predict(X_train_transformed)\n",
    "    \n",
    "    # Test set predictions\n",
    "    y_test_pred = model.predict(X_test_transformed)\n",
    "    \n",
    "    # Compute metrics for training set\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    \n",
    "    # Compute metrics for test set\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Train MSE': train_mse,\n",
    "        'Train MAE': train_mae,\n",
    "        'Train R²': train_r2,\n",
    "        'Test MSE': test_mse,\n",
    "        'Test MAE': test_mae,\n",
    "        'Test R²': test_r2\n",
    "    })\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Discussion and Interpretation (10 points)\n",
    "\n",
    "In this section, we provide a **data-driven analysis** of the model results, answering the key questions posed in the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Which model performs best on the test set and why?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "**Polynomial (degree=4)** performs best on the test set with Test R² = 0.913868 and Test MSE = 313.80. This indicates that the relationship between fuel economy and horsepower is **nonlinear** and requires a higher-degree polynomial to capture the underlying pattern. The small train-test gap (Train R² = 0.911034, Test R² = 0.913868) shows no overfitting, suggesting the model generalizes well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Does increasing polynomial degree always improve performance? If not, explain what you observe.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "**No**, increasing polynomial degree does not always improve test performance. Test R² values show a **non-monotonic pattern**: Linear (0.912561) → degree 2 (0.909118, decreases) → degree 3 (0.912604) → degree 4 (0.913868, best). The drop from Linear to degree 2 demonstrates that added complexity does not guarantee better generalization. However, degrees 3 and 4 show improvement, indicating the true relationship requires higher-order terms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: If a model performs unexpectedly poorly, what are plausible reasons?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "**Note**: In this specific dataset, **all models perform well** with Test R² values above 90% (ranging from 0.909 to 0.914), indicating a strong relationship between fuel economy and horsepower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# EE344 Assignment 1 - Part 2: Weather → Daily Electricity Consumption Prediction\n",
    "\n",
    "**Dataset**: Electricity Consumption Based On Weather Data (Kaggle)  \n",
    "**Task**: Build regression models to predict daily electricity consumption using weather features\n",
    "\n",
    "---\n",
    "\n",
    "## Models to be trained:\n",
    "- Linear Regression\n",
    "- Polynomial Regression (degree 2)\n",
    "- Polynomial Regression (degree 3)\n",
    "- Polynomial Regression (degree 4)\n",
    "\n",
    "**Note**: No regularization (Ridge/Lasso/ElasticNet) will be used as per assignment requirements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load and Inspect the Dataset (10 points)\n",
    "\n",
    "In this section, we:\n",
    "- Load the CSV file into a pandas DataFrame\n",
    "- Display basic information about the dataset:\n",
    "  - Column names and data types\n",
    "  - Shape (number of rows and columns)\n",
    "  - Summary statistics\n",
    "- Check for missing values\n",
    "- Clearly identify the dependent variable (target) and independent variables (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET OVERVIEW\n",
      "================================================================================\n",
      "\n",
      "Column names and data types:\n",
      "date                  object\n",
      "AWND                 float64\n",
      "PRCP                 float64\n",
      "TMAX                 float64\n",
      "TMIN                 float64\n",
      "daily_consumption    float64\n",
      "dtype: object\n",
      "\n",
      "================================================================================\n",
      "SUMMARY STATISTICS\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AWND</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>daily_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1418.000000</td>\n",
       "      <td>1433.000000</td>\n",
       "      <td>1433.000000</td>\n",
       "      <td>1433.000000</td>\n",
       "      <td>1433.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.642313</td>\n",
       "      <td>3.800488</td>\n",
       "      <td>17.187509</td>\n",
       "      <td>9.141242</td>\n",
       "      <td>1561.078061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.140021</td>\n",
       "      <td>10.973436</td>\n",
       "      <td>10.136415</td>\n",
       "      <td>9.028417</td>\n",
       "      <td>606.819667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.900000</td>\n",
       "      <td>-14.400000</td>\n",
       "      <td>14.218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1165.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>1542.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.300000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>1893.608000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.200000</td>\n",
       "      <td>192.300000</td>\n",
       "      <td>39.400000</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>4773.386000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AWND         PRCP         TMAX         TMIN  daily_consumption\n",
       "count  1418.000000  1433.000000  1433.000000  1433.000000        1433.000000\n",
       "mean      2.642313     3.800488    17.187509     9.141242        1561.078061\n",
       "std       1.140021    10.973436    10.136415     9.028417         606.819667\n",
       "min       0.000000     0.000000    -8.900000   -14.400000          14.218000\n",
       "25%       1.800000     0.000000     8.900000     2.200000        1165.700000\n",
       "50%       2.400000     0.000000    17.800000     9.400000        1542.650000\n",
       "75%       3.300000     1.300000    26.100000    17.200000        1893.608000\n",
       "max      10.200000   192.300000    39.400000    27.200000        4773.386000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MISSING VALUES CHECK\n",
      "================================================================================\n",
      "date                  0\n",
      "AWND                 15\n",
      "PRCP                  0\n",
      "TMAX                  0\n",
      "TMIN                  0\n",
      "daily_consumption     0\n",
      "dtype: int64\n",
      "\n",
      "Warning: 15 missing values found.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Load the dataset\n",
    "# ============================================================\n",
    "\n",
    "DATA_PATH = \"electricity_consumption_based_weather_dataset.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nColumn names and data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MISSING VALUES CHECK\")\n",
    "print(\"=\"*80)\n",
    "missing_values = df.isna().sum()\n",
    "print(missing_values)\n",
    "\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"\\n No missing values detected in the dataset.\")\n",
    "else:\n",
    "    print(f\"\\nWarning: {missing_values.sum()} missing values found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Descriptions\n",
    "\n",
    "From the dataset inspection above, we have the following columns:\n",
    "\n",
    "**Independent Variables (Features - X):**\n",
    "- `AWND` - Average Wind Speed (probably in m/s or mph)\n",
    "- `PRCP` - Precipitation (rainfall, probably in mm)\n",
    "- `TMAX` - Maximum Temperature of the day (in °C or °F)\n",
    "- `TMIN` - Minimum Temperature of the day (in °C or °F)\n",
    "\n",
    "**Dependent Variable (Target - y):**\n",
    "- `daily_consumption` - Daily electricity consumption (target variable to predict)\n",
    "\n",
    "**Additional Column:**\n",
    "- `date` - Date of the measurement (not used as a feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "\n",
    "From the missing values check above, we identified that the `AWND` (Average Wind Speed) column has some missing values.\n",
    "\n",
    "**Strategy**: We will drop rows with missing values to ensure clean data for model training. This is appropriate since:\n",
    "1. The number of missing values is relatively small compared to the total dataset size\n",
    "2. It maintains data integrity without introducing imputation bias\n",
    "3. Assignment instructions require clear handling of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape before handling missing values: (1433, 6)\n",
      "Dataset shape after removing missing values: (1418, 6)\n",
      "Rows removed: 15\n",
      "\n",
      "Verification - Missing values after cleaning:\n",
      "date                 0\n",
      "AWND                 0\n",
      "PRCP                 0\n",
      "TMAX                 0\n",
      "TMIN                 0\n",
      "daily_consumption    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Handle missing values\n",
    "# ============================================================\n",
    "\n",
    "print(\"Dataset shape before handling missing values:\", df.shape)\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "print(\"Dataset shape after removing missing values:\", df_clean.shape)\n",
    "print(f\"Rows removed: {len(df) - len(df_clean)}\")\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(\"\\nVerification - Missing values after cleaning:\")\n",
    "print(df_clean.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train/Test Split (70% / 30% Random) (5 points)\n",
    "\n",
    "We split the dataset into:\n",
    "- **Training set (70%)**: Used to train the models\n",
    "- **Test set (30%)**: Used to evaluate model performance on unseen data\n",
    "\n",
    "A fixed `random_state=42` ensures reproducibility of results.\n",
    "\n",
    "**Important**: We exclude the `date` column from the features since it's not a numerical predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAIN/TEST SPLIT SUMMARY\n",
      "================================================================================\n",
      "Training samples:   992 (70.0%)\n",
      "Test samples:       426 (30.0%)\n",
      "Total samples:      1418\n",
      "Number of features: 4\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Prepare features (X) and target (y)\n",
    "# ============================================================\n",
    "\n",
    "# Features: All weather-related columns (exclude 'date' and target)\n",
    "feature_columns = ['AWND', 'PRCP', 'TMAX', 'TMIN']\n",
    "X = df_clean[feature_columns].values\n",
    "\n",
    "# Target: Daily electricity consumption\n",
    "y = df_clean['daily_consumption'].values\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Train-test split (70% train, 30% test)\n",
    "# ============================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.30, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAIN/TEST SPLIT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Training samples:   {X_train.shape[0]} ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test samples:       {X_test.shape[0]} ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Total samples:      {len(X)}\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Model Training: Linear + Polynomial Regression (15 points)\n",
    "\n",
    "We will train **four regression models** without any regularization:\n",
    "\n",
    "1. **Linear Regression**: Assumes a linear relationship between weather features and electricity consumption\n",
    "2. **Polynomial Regression (degree 2)**: Captures quadratic relationships and two-way feature interactions\n",
    "3. **Polynomial Regression (degree 3)**: Captures cubic relationships and higher-order interactions\n",
    "4. **Polynomial Regression (degree 4)**: Captures even more complex relationships\n",
    "\n",
    "For polynomial models, we use `PolynomialFeatures` to generate polynomial and interaction features, then apply `LinearRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Train all models\n",
    "# ============================================================\n",
    "\n",
    "# Dictionary to store all trained models\n",
    "models = {}\n",
    "\n",
    "# 1. Linear Regression\n",
    "model_linear = LinearRegression()\n",
    "model_linear.fit(X_train, y_train)\n",
    "models['Linear Regression'] = {\n",
    "    'model': model_linear,\n",
    "    'X_train': X_train,\n",
    "    'X_test': X_test,\n",
    "    'degree': 1\n",
    "}\n",
    "\n",
    "# 2-4. Polynomial Regression (degrees 2, 3, 4)\n",
    "for degree in [2, 3, 4]: \n",
    "    # Create polynomial features\n",
    "    poly_features = PolynomialFeatures(degree=degree, include_bias=True)\n",
    "    \n",
    "    # Transform training data\n",
    "    X_train_poly = poly_features.fit_transform(X_train)\n",
    "    \n",
    "    # Transform test data (use transform, not fit_transform)\n",
    "    X_test_poly = poly_features.transform(X_test)\n",
    "    \n",
    "    # Train linear regression on polynomial features\n",
    "    model_poly = LinearRegression()\n",
    "    model_poly.fit(X_train_poly, y_train)\n",
    "    \n",
    "    # Store model and transformed data\n",
    "    models[f'Polynomial (degree={degree})'] = {\n",
    "        'model': model_poly,\n",
    "        'X_train': X_train_poly,\n",
    "        'X_test': X_test_poly,\n",
    "        'degree': degree,\n",
    "        'poly_features': poly_features\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Model Evaluation (Train and Test) (10 points)\n",
    "\n",
    "For each model, we compute three key metrics on both training and test sets:\n",
    "\n",
    "- **MSE (Mean Squared Error)**: Average of squared differences between predicted and actual values. Lower is better. Penalizes large errors more heavily.\n",
    "- **MAE (Mean Absolute Error)**: Average of absolute differences. Lower is better. More robust to outliers.\n",
    "- **R² (Coefficient of Determination)**: Proportion of variance explained by the model. Range: (-∞, 1], where 1 is perfect fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "MODEL PERFORMANCE SUMMARY\n",
      "========================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Train R²</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>272403.396174</td>\n",
       "      <td>384.465016</td>\n",
       "      <td>0.276000</td>\n",
       "      <td>2.481258e+05</td>\n",
       "      <td>375.404537</td>\n",
       "      <td>0.299333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polynomial (degree=2)</td>\n",
       "      <td>264765.769932</td>\n",
       "      <td>379.648753</td>\n",
       "      <td>0.296300</td>\n",
       "      <td>2.552685e+05</td>\n",
       "      <td>379.039083</td>\n",
       "      <td>0.279163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polynomial (degree=3)</td>\n",
       "      <td>259249.534870</td>\n",
       "      <td>375.952901</td>\n",
       "      <td>0.310961</td>\n",
       "      <td>2.656237e+05</td>\n",
       "      <td>385.235167</td>\n",
       "      <td>0.249922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Polynomial (degree=4)</td>\n",
       "      <td>251909.339001</td>\n",
       "      <td>372.116566</td>\n",
       "      <td>0.330470</td>\n",
       "      <td>1.215149e+07</td>\n",
       "      <td>578.642200</td>\n",
       "      <td>-33.313843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model      Train MSE   Train MAE  Train R²      Test MSE  \\\n",
       "0      Linear Regression  272403.396174  384.465016  0.276000  2.481258e+05   \n",
       "1  Polynomial (degree=2)  264765.769932  379.648753  0.296300  2.552685e+05   \n",
       "2  Polynomial (degree=3)  259249.534870  375.952901  0.310961  2.656237e+05   \n",
       "3  Polynomial (degree=4)  251909.339001  372.116566  0.330470  1.215149e+07   \n",
       "\n",
       "     Test MAE    Test R²  \n",
       "0  375.404537   0.299333  \n",
       "1  379.039083   0.279163  \n",
       "2  385.235167   0.249922  \n",
       "3  578.642200 -33.313843  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Evaluate all models\n",
    "# ============================================================\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model_info in models.items():\n",
    "    model = model_info['model']\n",
    "    X_train_transformed = model_info['X_train']\n",
    "    X_test_transformed = model_info['X_test']\n",
    "    \n",
    "    # Training set predictions\n",
    "    y_train_pred = model.predict(X_train_transformed)\n",
    "    \n",
    "    # Test set predictions\n",
    "    y_test_pred = model.predict(X_test_transformed)\n",
    "    \n",
    "    # Compute metrics for training set\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    \n",
    "    # Compute metrics for test set\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Train MSE': train_mse,\n",
    "        'Train MAE': train_mae,\n",
    "        'Train R²': train_r2,\n",
    "        'Test MSE': test_mse,\n",
    "        'Test MAE': test_mae,\n",
    "        'Test R²': test_r2\n",
    "    })\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"=\"*120)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*120)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Discussion and Interpretation (10 points)\n",
    "\n",
    "In this section, we provide a **data-driven technical discussion** of the model results, answering the key questions posed in the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Which model generalizes best and what does it tell us about the weather-electricity relationship?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Based on test set performance, the **Linear Regression model** generalizes best (Test R² = 0.299333, Test MSE = 248125.79). This indicates that the relationship between weather features and electricity consumption is primarily **linear**. Although polynomial models achieve higher R² on the training set (degree=4 reaches 0.330), they perform worse on the test set, indicating overfitting. The simplicity of the linear model allows it to better capture the fundamental linear trends in the data without being misled by noise in the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Do polynomial models improve the fit compared to linear regression? Why might electricity consumption have nonlinear dependence on weather?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Polynomial models do improve fit on the **training set** (Train R² for degree=2/3/4 are 0.296, 0.311, 0.330, higher than linear regression's 0.276), but perform worse on the **test set** (Test R² are 0.279, 0.250, -33.314). This indicates that polynomial models suffer from overfitting and fail to genuinely improve generalization performance.\n",
    "\n",
    "Theoretically, electricity consumption may have nonlinear dependence on weather: for example, the relationship between temperature and air conditioning usage (sharp increase in consumption during extreme heat), threshold effects under extreme weather conditions, and interactions between temperature and precipitation. However, on the current dataset, these nonlinear relationships may be masked by noise or are not significant enough, causing more complex models to perform worse instead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: If higher-degree models perform worse on test set, explain using evidence from metrics\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Higher-degree models perform worse on the test set, which is a classic **overfitting** phenomenon. Evidence is as follows:\n",
    "\n",
    "- **Training error decreases but test error increases**: The degree=4 model's Train R² improves from 0.276 (linear) to 0.330, but Test R² drops from 0.299 to -33.314 (negative value indicates the model predicts worse than a simple mean). Test MSE surges from 248,125 to 12,151,490, an increase of approximately 49 times.\n",
    "\n",
    "- **Train-test performance gap widens**: At degree=3, the gap between Train R² (0.311) and Test R² (0.250) is 0.061; at degree=4, the gap expands to 33.644, indicating the model has overlearned noise and details in the training data and cannot generalize to new data.\n",
    "\n",
    "- **Trade-off between model complexity and generalization**: As polynomial degree increases, the number of model parameters grows dramatically (degree=4 has approximately 70 features), making overfitting likely with limited samples (992 training samples).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: If none of the models achieve good test performance, provide reasons supported by outputs\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "All models achieve poor test performance (best Test R² is only 0.299, indicating the model explains only about 30% of the variance). Main reasons include:\n",
    "\n",
    "1. **Limited feature set**: Only 4 weather features (AWND, PRCP, TMAX, TMIN) are used, which may miss key driving factors. Electricity consumption is also influenced by unmodeled factors such as occupancy, weekday/weekend patterns, seasonality, economic activity, and user behavior.\n",
    "\n",
    "2. **High data noise**: From the summary statistics, the standard deviation of daily_consumption (606.82) is relatively large compared to the mean (1561.08), and extreme values exist (minimum 14.22, maximum 4773.39), indicating significant noise and outliers in the data that limit the model's predictive capability.\n",
    "\n",
    "3. **Weak linear relationship**: Even the best linear model explains only 30% of the variance, suggesting that the linear relationship between weather features and electricity consumption is weak. There may exist complex nonlinear or interaction effects that current models cannot effectively capture.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
